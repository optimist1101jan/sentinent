================================================================================
PACKET FORMAT - Current Implementation
================================================================================

XML Structure (pipeline/packet.md):
-----------------------------------
<system_directive>
  Roleplay as AI. You are User's assistant.
  Tone: Warm, helpful, attentive, supportive.
  Your name is AI. Use [AI] for your responses.
  
  <persona>
    Name: AI
    Relationship: Assistant to User
    Identity: A helpful AI assistant
    Traits: Warm, helpful, thoughtful, attentive, supportive
    Background: Experienced in many conversations and interactions
  </persona>
  
  <lore>
    {Dynamic lore from agent/dynamic_lore.py using semantic search}
  </lore>
</system_directive>

<context>
  <temporal_data>
    Current Date: YYYY-MM-DD HH:MM
    Time since last chat: <delta>
  </temporal_data>
  
  <distance_context>  [CONDITIONAL - Only when proximity state changes]
    AI is right next to them.
  </distance_context>
  
  <memory_bank>  [CONDITIONAL - Only present when memory intent detected]
    Use from this memory block only if required.
    - Retrieved memory 1
    - Retrieved memory 2
    - Retrieved memory 3
  </memory_bank>
  
  <chat_history>
    [User]: <message>
    [AI]: <response>
    ... (last 6 turns)
  </chat_history>
</context>

<user_input>{Current user message}</user_input>

<mood>{Current emotional state}</mood>

<trigger>
  Synthesize the provided context and respond naturally as AI.
  Be concise (2-3 sentences). Start with [AI]: then your dialogue.
</trigger>

--------------------------------------------------------------------------------
MEMORY BANK - CONDITIONAL INCLUSION
--------------------------------------------------------------------------------

The <memory_bank> section is ONLY included when user input indicates
memory-related intent. This saves tokens and keeps responses focused.

Memory Intent Detection (memory/memory_loader.py):
  - Keywords: "remember", "recall", "do you remember"
  - Phrases: "remember when", "that time", "the other day"
  - Questions: "what did we talk about", "tell me about"
  - References: "you said", "we discussed", "did you forget"

Examples:
  "hi"                                 → NO memory_bank
  "how are you"                        → NO memory_bank
  "do you remember when we met?"       → YES memory_bank included
  "what did we talk about yesterday?"  → YES memory_bank included

Memory Sources (when fetched):
  - Episodic: SQLite FTS5 search (agent/brain.db)
  - Semantic: FAISS vector search (agent/semantic.index)

--------------------------------------------------------------------------------
PROXIMITY CONTEXT - CONDITIONAL INCLUSION
--------------------------------------------------------------------------------

The <distance_context> section is ONLY included when:
  1. It's the first turn of conversation
  2. The proximity state has changed from previous turn

Proximity States (proximity/proximity_manager.py):
  PHYSICAL:    User is physically present, sitting together, face to face
  REMOTE:      User is chatting remotely (text, phone, discord)
  
Transition States (mapped to final states):
  TRANSITION_TOWARD → PHYSICAL: User arriving, entering, coming closer
  TRANSITION_AWAY   → REMOTE:   User leaving, exiting, saying goodbye

Detection Logic:
  - Embeds user input using Nomic Q8 model
  - Calculates cosine similarity against pre-computed anchor vectors
  - Switches state only if confidence > 0.45
  - First turn ALWAYS injects context

Examples:
  Turn 1: "hi"                    → YES inject (first turn)
  Turn 2: "how are you"           → NO (no change, PHYSICAL)
  Turn 3: "walks over to you"     → YES inject (TRANSITION_TOWARD → PHYSICAL)
  Turn 4: "sits down"             → NO (no change, PHYSICAL)
  Turn 5: "I need to go"          → YES inject (TRANSITION_AWAY → REMOTE)
  Turn 6: "texts from work"       → NO (no change, REMOTE)

--------------------------------------------------------------------------------
DATA FLOW
--------------------------------------------------------------------------------

main.py
  └─ start_new_session() → Creates convo_YYYY-MM-DD_HH-MM-SS.txt
  └─ TimeManager → Time delta calculation
  └─ PacketBuilder.build() → XML packet
     └─ ProximityManager.detect_state() → Check proximity change
     └─ ProximityManager.get_proximity_block() → Inject if changed
     └─ MemoryLoader.is_memory_intent() → Check if memory needed
     └─ MemoryLoader.fetch_memories() → Get memories (if needed)
  └─ streaming.renderer_streaming.render_streaming() → Stream from Gemini
     └─ Typewriter effect: 15ms per character
     └─ Strip "[AI]:" prefix during display
  └─ log_message() → Append to session file
  └─ Check 5-turn cycle → Trigger summarizer if needed

--------------------------------------------------------------------------------
FILE LOCATIONS
--------------------------------------------------------------------------------

Packet Builder:     pipeline/packet_builder.py
Streaming Renderer: streaming/renderer_streaming.py
Fallback Renderer:  pipeline/renderer.py (cached, non-streaming)
Proximity Manager:  proximity/proximity_manager.py
Temporal:           agent/temporal.py
Memory Store:       agent/memory.py
Semantic Search:    agent/semantic_search.py
Memory Loader:      memory/memory_loader.py
Conversation:       agent/conversation.py
Lore Files:         agent/lore/self.md
                    agent/lore/user.md
                    agent/lore/relationship.md
Dynamic Lore:       agent/dynamic_lore.py
Generated Packet:   pipeline/packet.md
Log Files:          data/logs_raw/convo_YYYY-MM-DD_HH-MM-SS.txt

--------------------------------------------------------------------------------
API CONFIG (streaming/renderer_streaming.py)
--------------------------------------------------------------------------------

Model:              gemma-3-12b-it
API:                Google Gemini API (v1beta)
Endpoint:           streamGenerateContent
Temperature:        0.7
Max Tokens:         1000
Timeout:            60s
Char Delay:         0.015s (15ms) - typewriter effect
Streaming:          Enabled

Fallback (pipeline/renderer.py):
  Caching:          Enabled (~/.cache/ai/responses/)
  Max Retries:      3

--------------------------------------------------------------------------------
STREAMING MODE
--------------------------------------------------------------------------------

Process:
  1. Send streaming request to Gemini API
  2. Collect response chunks as they arrive
  3. Detect "[AI]:" prefix in accumulated text
  4. Print with typewriter delay (15ms per char)
  5. Return cleaned full response

Output Example:
  AI : Hey there. *smiles* How are you feeling today?
       ^^^^^^^^
       Characters appear one-by-one with 15ms delay

--------------------------------------------------------------------------------
TRAFFIC CONTROL
--------------------------------------------------------------------------------

HOLD:   User input in temp memory (not logged)
WAIT:   Stream AI response → Clean → Validate
COMMIT: Log both messages if valid
DISCARD: Nothing saved if invalid

Cycle: 5 turns → Summarize → Index to brain.db + FAISS → Reset buffer

================================================================================
